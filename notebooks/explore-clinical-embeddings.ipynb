{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore clinical embeddings\n",
    "\n",
    "This example explores how you would convert text into a numerical vector of clinical embeddings and look for matches.\n",
    "\n",
    "This is from the [Weissman lab](https://github.com/weissman-lab/clinical_embeddings)\n",
    "\n",
    "I downloaded [https://github.com/weissman-lab/clinical_embeddings?tab=readme-ov-file] (https://github.com/weissman-lab/clinical_embeddings?tab=readme-ov-file) - the 100 dimension model trained on open access reports only. Downloaded to file manager UCLH remote desktop, unzipped tar.gz to tar, then tar to folders. Then uploaded into Jupyter environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload functions every time\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Import the variables that have been set in the init.py folder in the root directory\n",
    "# These include a constant called PROJECT_ROOT which stores the absolute path to this folder\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "import init\n",
    "PROJECT_ROOT = os.getenv(\"PROJECT_ROOT\")\n",
    "\n",
    "# Add the src folder to sys path, so that the application knows to look there for libraries\n",
    "sys.path.append(str(Path(PROJECT_ROOT) / 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.9.3)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-7.0.1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wrapt, smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-7.0.1 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText, Word2Vec, KeyedVectors # KeyedVectors are used to load the GloVe models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w2v_OA_CR_100d.bin.wv.vectors.npy',\n",
       " 'w2v_OA_CR_100d.bin',\n",
       " 'w2v_OA_CR_100d.bin.trainables.syn1neg.npy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_path = Path(PROJECT_ROOT) / 'data_store/clinical_embeddings/W2V_100'\n",
    "os.listdir(str(embeddings_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "# model = Word2Vec.load(str(embeddings_path) + '/w2v_oa_all_100d.bin') # for Open Access All Manuscripts\n",
    "model = Word2Vec.load(str(embeddings_path) + '/w2v_OA_CR_100d.bin') # for Case Reports only\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75374293"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return 100-dimensional vector representations of each word\n",
    "model.wv.get_vector('diabetes')\n",
    "model.wv.get_vector('cardiac_arrest')\n",
    "model.wv.get_vector('lymphangioleiomyomatosis')\n",
    "\n",
    "# Try out cosine similarity\n",
    "model.wv.similarity('copd', 'chronic_obstructive_pulmonary_disease')\n",
    "model.wv.similarity('myocardial_infarction', 'heart_attack')\n",
    "model.wv.similarity('lymphangioleiomyomatosis', 'lam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8092604\n",
      "0.2948834\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.similarity('vodka', 'drinking'))\n",
    "print(model.wv.similarity('vodka', 'myocardial_infarction'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7921261"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('myocardial_infarction', 'heart_attack')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86180943"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('copd', 'chronic_obstructive_pulmonary_disease')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12271345"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('discharge', 'tta' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load notes from Jon project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "notes = pd.read_csv('/home/jovyan/work/zella/zbeds/explore/discharges/data-raw/discharges_jon_2023-02-17.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_vectors(df, model):\n",
    "    valid_vectors = set()\n",
    "    for text in df['note']:\n",
    "        unique_words = set(text.split())\n",
    "        for word in unique_words:\n",
    "            try:\n",
    "                model.wv.get_vector(word)\n",
    "                valid_vectors.add(word)\n",
    "            except KeyError:\n",
    "                continue\n",
    "    return list(valid_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_words = get_valid_vectors(notes, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['home', '1.0'],\n",
       "       ['apartment', '0.7666387'],\n",
       "       ['supermarket', '0.7521133'],\n",
       "       ['taxi', '0.744518'],\n",
       "       ['hired', '0.7438201'],\n",
       "       ['attendance', '0.7428458'],\n",
       "       ['hotel', '0.74082637'],\n",
       "       ['rehab', '0.7370461'],\n",
       "       ['midwife', '0.73629725'],\n",
       "       ['daycare', '0.73576784']], dtype='<U32')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = np.array([(word, model.wv.similarity('home', word)) for word in found_words])\n",
    "similarities[np.argsort(similarities[:, 1].astype(float))[::-1][:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['discharge', '1.0'],\n",
       "       ['admission', '0.6673033'],\n",
       "       ['discharging', '0.6502145'],\n",
       "       ['admittance', '0.6492708'],\n",
       "       ['flatus', '0.64832884'],\n",
       "       ['foul', '0.6476266'],\n",
       "       ['defecating', '0.6340597'],\n",
       "       ['oozing', '0.6292507'],\n",
       "       ['complaints', '0.6285596'],\n",
       "       ['urinated', '0.6284532']], dtype='<U32')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = np.array([(word, model.wv.similarity('discharge', word)) for word in found_words])\n",
    "similarities[np.argsort(similarities[:, 1].astype(float))[::-1][:10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
